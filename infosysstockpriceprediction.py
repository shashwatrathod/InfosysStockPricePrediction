# -*- coding: utf-8 -*-
"""InfosysStockPricePrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SN3Ay2AlZ2MhU-KJsRerl0bcPORieNHF

# Predicting Stock Prices of Infosys
"""

import pandas_datareader as web
from datetime import datetime
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import CuDNNLSTM, Dense
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import TensorBoard
import matplotlib.pyplot as plt
import pickle
import time

plt.style.use('fivethirtyeight')

"""BUFFER is the number of past closing prices used to predict the next closing price.
I experimented with various epochs and buffer size but found this to be working best.
"""

BUFFER = 90
LEARNING_RATE = 0.001
EPOCHS = 4

today = datetime.today().strftime('%d-%m-%y')
df = web.DataReader('INFY',data_source='yahoo',start='20-02-2005', end=today)
print(df.tail())

closing_data = df['Close']
plt.figure(1,figsize=(16,7))
plt.plot(closing_data)
plt.title('INFOSYS STOCK CLOSING PRICES', fontsize=22)
plt.ylabel('Price(in USD)', fontsize=18)
plt.xlabel('Date', fontsize=18)
plt.show()

"""## Test-Train Split"""

c_data = closing_data.to_numpy()
train_split_ratio = 0.8
train_index = int(np.ceil(closing_data.shape[0]*train_split_ratio))
print(train_index)
training_data = c_data[:train_index]
test_data = c_data[train_index:]
print(f"Training data shape: {training_data.shape}")
print(f"Test data shape: {test_data.shape}")

"""## Normalization"""

def fit_transform(X):
  norm_factors=[]
  if(len(X.shape)==1):
    norm_factors.append(np.max(X))
    X = X/np.max(X)
  else:
    for col in range(X.shape[1]):
      norm_factors.append(np.max(X[:,col]))
      X[:,col] = X[:,col]/np.max(X[:,col])
  
  with open("normalization_factors.pkl","wb") as f:
    pickle.dump(norm_factors,f)
  
  X = np.asarray(X)
  return X,norm_factors

def inverse_transform(X):
  with open("normalization_factors.pkl","rb") as f:
    norm_factors = pickle.load(f)
  
  X = X*norm_factors
  return X

def transform(X):
  with open("normalization_factors.pkl","rb") as f:
    norm_factors = pickle.load(f)
  
  return X/norm_factors

training_data_scaled,norm_factors = fit_transform(training_data)
print(training_data_scaled)
print(training_data_scaled.shape)

"""## X-y split"""

def X_y_split(data, buffer):
  X = []
  y = []
  for i in range(buffer,data.shape[0]):
    X.append(data[i-buffer:i])
    y.append(data[i])
  
  return np.asarray(X),np.asarray(y)

train_x,train_y = X_y_split(training_data_scaled,BUFFER)
print(train_x[:2])
print(train_y[:2])

test_data_scaled = transform(test_data)
test_x,test_y = X_y_split(test_data_scaled,BUFFER)
print(test_x[:2])
print(test_y[:2])

"""## Creating the model"""

train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))
test_x = np.reshape(test_x, (test_x.shape[0], test_x.shape[1], 1))

model = Sequential()
model.add(CuDNNLSTM(units=BUFFER,input_shape=(train_x.shape[1],1),return_sequences=True))
model.add(CuDNNLSTM(units=BUFFER,input_shape=(train_x.shape[1],1),return_sequences=False))
model.add(Dense(units=BUFFER-20,activation='relu'))
model.add(Dense(units=1,activation='relu'))

optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)
model.compile(optimizer=optimizer,
              loss='mse',
              metrics=['accuracy'])

name = f"STOCKPRED-{int(time.time())}"
tensorboard = TensorBoard(log_dir=f"logs/{name}")
print(train_x.shape)
print(test_x.shape)

"""## Training"""

model.fit(train_x, train_y,
          batch_size=1,
          epochs=EPOCHS,
          callbacks=[tensorboard],
          validation_data=(test_x,test_y))

"""## Here come the predictions!"""

predicted = model.predict(test_x)

plt.figure(figsize=(15,8))
plt.plot(inverse_transform(test_y))
plt.plot(inverse_transform(predicted))
plt.xlabel('Days')
plt.ylabel('Price(in USD)')
plt.title('Pred vs Actual')
plt.legend(['TEST','PREDICTED'],loc='lower right')

model.save(f"models/{name}")

def predict_next_date():
  today = datetime.today().strftime('%d-%m-%y')
  df = web.DataReader('INFY',data_source='yahoo',start='20-02-2010', end=today)
  closing_data = df['Close']
  test_next = np.asarray(closing_data[-BUFFER:])
  test_next = transform(test_next)
  test_n = []
  test_n.append(test_next[0:BUFFER])
  test_n = np.asarray(test_n)
  test_n = np.reshape(test_n,(test_n.shape[0],test_n.shape[1],1))
  pred_n = model.predict(test_n)
  pred_inv = inverse_transform(pred_n)
  print(f'Next date\'s prediction: USD {pred_inv[0,0]}')

predict_next_date()